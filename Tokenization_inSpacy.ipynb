{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cc4111-86da-48d0-8529-cdcec1f1e2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81802e7-4324-4128-97c4-170803d22faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633a707f-5da4-49ec-96bb-e49eb944fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chem,\n",
       " loves,\n",
       " to,\n",
       " eat,\n",
       " Panipuri,\n",
       " .,\n",
       " He,\n",
       " also,\n",
       " loves,\n",
       " to,\n",
       " eat,\n",
       " other,\n",
       " masala,\n",
       " items]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Chem loves to eat Panipuri. He also loves to eat other masala items\")\n",
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f94f933-a1e1-47a4-b534-af6e0356b5fe",
   "metadata": {},
   "source": [
    "i.e. Creating a blank language object gives a tokenizer and an empty pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaf08a8-5f37-43f0-9bf7-3271cfcb5905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chem"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index to grab tokens\n",
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e997ec-036c-4e65-9635-616340211f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to eat Panipuri"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37b47e5-cca1-4d6e-a7d5-91b8b42a3b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = doc[0]\n",
    "#dir(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2de57e-c2dc-40fd-b958-cddd0bd2b2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1c113e-a86f-450f-a9cb-c19690b6a7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51ee040e-5532-4699-908f-8e4fe588cce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a7a998-e364-4260-ba73-e60a1bd086b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names # i.e. Checking for nlp pipe_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d973451-9708-46f7-b23a-3977239a71ee",
   "metadata": {},
   "source": [
    "Token Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb3ce2f-5952-4d93-917a-9b849849a913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp('Chem has 2$ which he intends to buys two sandwiches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86043253-ec92-476c-a6f0-e7e3595a2e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[2]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a92f0e16-8796-4236-8114-61eb6a4aa2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0938d76-d565-4939-92f4-64cb8128d7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = doc[9]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6699975e-d077-4d08-b17e-c60dab220eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94838a12-298f-4452-89ab-f4356157feaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = doc[3]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bb0b70a-e4e3-4ef4-a8f8-85df2d4ece39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa58ab6d-a16c-4934-819e-99df28f0063e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chem"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3 = doc[0]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26e53cc5-38da-46c1-bd32-9bc280fbb07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3.is_alpha # i.e. Chem is an alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f1c0dd5-551c-4c2d-9ee2-8f76f95636f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chem ===> index: 0 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "has ===> index: 1 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "2 ===> index: 2 is Alphabet: False is Number: True is Currency: False is Punctuation: False\n",
      "$ ===> index: 3 is Alphabet: False is Number: False is Currency: True is Punctuation: False\n",
      "which ===> index: 4 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "he ===> index: 5 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "intends ===> index: 6 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "to ===> index: 7 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "buys ===> index: 8 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n",
      "two ===> index: 9 is Alphabet: True is Number: True is Currency: False is Punctuation: False\n",
      "sandwiches ===> index: 10 is Alphabet: True is Number: False is Currency: False is Punctuation: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,\"===> index:\",token.i,\n",
    "          \"is Alphabet:\",token.is_alpha,\n",
    "          \"is Number:\",token.like_num,\n",
    "          \"is Currency:\",token.is_currency,\n",
    "          \"is Punctuation:\",token.is_punct)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff8dcb8a-dbe4-43b0-a1f2-08fb2c491e50",
   "metadata": {},
   "source": [
    "Collecting email ids from the list given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8eb552d2-4c6a-42bb-be29-c0fdac6d3a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This tutorial is about Natural Language Processing in spacy\\n',\n",
       " 'Some of the email ids are:\\n',\n",
       " 'kaimohtaham8020@gmail.com\\n',\n",
       " 'kaimohtaham@gmail.com\\n',\n",
       " 'RakeshTalukdar2034@gmail.com\\n',\n",
       " 'RameshBabu@gmail.com']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from the lines\n",
    "with open(\"NLP.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18cdd14f-f5d0-4579-a430-8e6af1306deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This tutorial is about Natural Language Processing in spacy\\nSome of the email ids are:\\nkaimohtaham8020@gmail.com\\nkaimohtaham@gmail.com\\nRakeshTalukdar2034@gmail.com\\nRameshBabu@gmail.com'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e98d2ede-fd1f-4fd9-955e-19e8d2048948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc1 = nlp(text)\n",
    "email = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16865c8e-9aab-415e-9e47-be4c594303f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaimohtaham8020@gmail.com',\n",
       " 'kaimohtaham@gmail.com',\n",
       " 'RakeshTalukdar2034@gmail.com',\n",
       " 'RameshBabu@gmail.com']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    if token.like_email:\n",
    "        email.append(token.text)\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c896c063-8d53-4255-bca7-e7d9d0e85412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaimohtaham8020@gmail.com',\n",
       " 'kaimohtaham@gmail.com',\n",
       " 'RakeshTalukdar2034@gmail.com',\n",
       " 'RameshBabu@gmail.com']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email2 = []\n",
    "[email2.append(token.text) for token in doc1 if token.like_email]\n",
    "email2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4980a362-6fb2-4f2c-9efc-e999269ff97a",
   "metadata": {},
   "source": [
    "Support in other languages:\n",
    "    - i.e.Spacy supports various language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3de1894-722d-413f-bbce-297a2a9f93cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09d8c858-de51-4106-9082-4b2581089fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[केम,\n",
       " को,\n",
       " ₹,\n",
       " 500,\n",
       " रुपये,\n",
       " की,\n",
       " जरूरत,\n",
       " है,\n",
       " .,\n",
       " वह,\n",
       " इसे,\n",
       " कुल,\n",
       " मिलाकर,\n",
       " 5,\n",
       " दोस्तों,\n",
       " से,\n",
       " उधार,\n",
       " लेना,\n",
       " चाहता,\n",
       " है,\n",
       " ।]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"केम को ₹ 500 रुपये की जरूरत है. वह इसे कुल मिलाकर 5 दोस्तों से उधार लेना चाहता है।\")\n",
    "[token for token in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bfea5b7-678d-42c9-a074-f0c7e1beabe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc1 if token.is_currency]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd356bf2-1f76-4b1f-887d-efd6c9f362bd",
   "metadata": {},
   "source": [
    "Customizing Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d1c1ef1-f7b1-4bf1-9e6c-8ef6e8d58fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc3 = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc3]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae2cd80a-3a2f-466b-835f-5780e6a4a010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"},\n",
    "])\n",
    "doc3 = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc3]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "456d62b9-f96a-42a9-aeea-2090fb13450d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m''' Sentence Tokenizer or Segmentation '''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentence)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:923\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "''' Sentence Tokenizer or Segmentation '''\n",
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "625825c8-ced5-4a22-892a-311d3bc4db98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1fb1b04cd10>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90a19b05-6b86-43ad-80bb-cec1bfa5c7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d09efdac-5023-475f-8b93-a24fe9caaa95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x1fb1b04cd10>)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
